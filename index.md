---
layout: default
title: About
---

<div class="hero-section">
  <div class="hero-content">
    <div class="hero-text">
      <p class="hero-description">
        I'm an <strong>AI Research Scientist</strong> at the <a href="https://ai.ethz.ch/" target="_blank">ETH AI Center</a> and co-leader of the LLM effort of the <a href="https://www.swiss-ai.org/" target="_blank">Swiss AI Initiative</a>. With a large team of engineers, researchers, and students throughout multiple Swiss institutions, we are currently developing the largest <strong>open-source and responsibly-trained large language model</strong> (LLM) in the world. I also teach a novel course at ETHZ called <a href="https://ai.ethz.ch/education/courses/large-scale-ai-engineering.html" target="_blank">Large-Scale AI Engineering</a>, where we provide hands-on, practical training to MSc graduates on how to efficiently train large distributed neural networks using the Alps supercomputer.
      </p>
      
      <p class="hero-description">
        <strong>Bio.</strong> I began my career with an apprenticeship in informatics at a Swiss bank and my military service. I then earned my BSc in Computer Science from FHNW and MSc in Artificial Intelligence with distinction from the University of St Andrews, Scotland. I completed my PhD with distinction at USI/IDSIA under <a href="https://people.idsia.ch/~juergen/" target="_blank">Prof. Jürgen Schmidhuber</a> in 2023, focusing on systematic generalisation of neural networks and fast weight programmers—scalable self-modifying neural architectures <a href="https://susi.usi.ch/usi/documents/326257" target="_blank">(thesis)</a>. My research journey included internships at Meta FAIR, Google Research, and Microsoft Research, where I explored foundational questions in neural computation, scalable neural network architectures, and LLMs. After my PhD I worked with <a href="https://da.inf.ethz.ch/people/ThomasHofmann/" target="_blank">Prof. Thomas Hofmann</a> before moving to the ETHZ AI Center.
      </p>
      
    </div>
    
    <div class="hero-image">
      <img src="/assets/images/imanol-schlag.png" alt="**Imanol Schlag**" class="profile-photo">
      <div class="social-icons">
        <a href="mailto:ischlag@ethz.ch">[email]</a>
        <a href="https://scholar.google.com/citations?user=nFQJEskAAAAJ" target="_blank">[Google Scholar]</a>
        <a href="https://github.com/ischlag" target="_blank">[GitHub]</a>
        <a href="https://twitter.com/imanolschlag" target="_blank">[Twitter/X]</a>
        <a href="https://www.linkedin.com/in/imanol-schlag-609b65b0/" target="_blank">[LinkedIn]</a>
      </div>
    </div>
  </div>
</div>

<section class="opportunities-section">
  <h2>Opportunities</h2>
  
  <p><strong>Students.</strong> We welcome motivated MSc students from ETHZ, EPFL, and other universities to join our research efforts through a semester project, MSc thesis, or a student assistant position. We offer research and engineering opportunities across various topics like LLM development, high-performance infrastructure, and responsible AI. Students can apply through our <a href="https://forms.gle/Hm7RSzrECMUiTRyT7" target="_blank">application form</a>.</p>
  
  <p><strong>Engineers.</strong> We're actively hiring machine learning research engineers to join our team developing cutting-edge foundation models in collaboration with researchers through the Swiss AI Initiative. Open positions are available through <a href="https://jobs.ethz.ch/job/view/JOPG_ethz_y0arocZ2u7u6EVaUhH" target="_blank">ETHZ</a> or <a href="https://www.linkedin.com/jobs/view/4223836781/" target="_blank">EPFL</a>.</p>
</section>

<section class="about-section">
  <h2>Research Focus</h2>
  <p>My research centers on three interconnected areas that advance both the capabilities and responsibility of large-scale AI systems.</p>
  
  <p><strong>First</strong>, I focus on developing state-of-the-art open-source LLMs that are transparent and compliant with current legal frameworks. This work provides a foundation for society to build trustworthy AI products and services while enabling researchers to better understand the benefits and risks of LLM-based systems.</p>
  
  <p><strong>Second</strong>, I advance neural architecture research through fast weight programmers such as the <a href="https://proceedings.mlr.press/v139/schlag21a" target="_blank">DeltaNet</a>, which contributes to the most significant architectural innovation since the rise of the Transformer. Similar to linear RNNs, like Mamba or RWKV, it offers enhanced efficiency and generality compared to attention-based architectures.</p>
  
  <p><strong>Third</strong>, I investigate fundamental questions around LLM scaling and generalisation. In particular, how to train these systems more efficiently and enable them to generalise beyond their current limitations. This includes exploring self-modifying neural networks as a pathway toward more general AI systems.</p>
  
  <p><a href="/research/" class="research-link">Read more</a></p>
</section>

<section class="news-section">
  <h2>Recent News</h2>
  <div class="news-items">
    <p><span class="news-date">Jul 2025</span> — <a href="https://www.youtube.com/watch?v=o6fF8w91emU" target="_blank">Prompt Zero Podcast</a> appearance by Blick (in Swiss German)</p>
    <p><span class="news-date">Jul 2025</span> — Keynote at the first <a href="https://lu.ma/pfjxc8v9" target="_blank">International Open-Source Model Builder Summit</a> before the AI for Good Summit in Geneva</p>
    <p><span class="news-date">Jun 2025</span> — <a href="https://www.startupticker.ch/en/events/pan-talk-swiss-ai-initiative-der-weg-zur-ki-souveraenitaet" target="_blank">pan.talk keynote</a> on Swiss AI Initiative: The Path to AI Sovereignty</p>
    <p><span class="news-date">Jun 2025</span> — Grant accepted "A Swiss-Centric Foundation Model for Switzerland's Sovereign AI Future"</p>
    <p><span class="news-date">Jun 2025</span> — Grant accepted "Democratizing LLMs for Global Languages with Mixtures of Multilingual Experts"</p>
    <p><span class="news-date">Jun 2025</span> — Successfully taught the first iteration of our MSc course at ETHZ: Large-Scale AI Engineering</p>
    <p><span class="news-date">May 2025</span> — Presentation of the Swiss AI Initiative to European Commission with EU delegation from each member state</p>
    <p><span class="news-date">May 2025</span> — Invited talk at <a href="https://blog.fhgr.ch/ai/ki-an-der-fh-graubuenden/" target="_blank">FH Graubünden AI event</a> presenting the Swiss AI Initiative and our LLM effort</p>
    <p><span class="news-date">Mar 2025</span> — <a href="https://www.linkedin.com/posts/schulthess-juristische-medien-ag_die-swiss-legal-tech-conference-versammelte-activity-7308510132907208705-cHxI" target="_blank">Keynote at Swiss Legal Tech Conference</a></p>
    <p><span class="news-date">Mar 2025</span> — <a href="https://www.ai-in-marketing.ch/" target="_blank">Keynote at the AI in Marketing conference</a> (400+ people)</p>
    <p><span class="news-date">Mar 2025</span> — Invited talk at <a href="https://www.hpcadvisorycouncil.com/events/2025/swiss-conference/" target="_blank">HPC-AI Conference</a> on the Swiss AI Initiative and our LLM Effort</p>
    <p><span class="news-date">Mar 2025</span> — Invited talk at <a href="https://www.linkedin.com/posts/gen-ai-360_its-coming-the-next-genai-360-will-be-activity-7301179082560405505-u4Tq" target="_blank">GenAI 360</a></p>
    <p><span class="news-date">Mar 2025</span> — <a href="https://squirro.com/squirro-podcast/dr-imanol-schlag-pioneering-the-future-of-ai" target="_blank">Redefining AI Podcast</a> appearance (Season 3, Ep. 17)</p>
    <p><span class="news-date">Mar 2025</span> — Expert input to <a href="https://www.srf.ch/wissen/kuenstliche-intelligenz/denken-auf-knopfdruck-warum-chatgpt-jetzt-selbstgespraeche-fuehrt" target="_blank">SRF Echo der Zeit</a> episode</p>
    <p><span class="news-date">Dec 2024</span> — <a href="https://www.zurichai.ch/events/zurichnlp-14" target="_blank">Zürich NLP Meetup</a> talk on "The Swiss AI LLM Effort: Building Transparent and Responsible AI for Switzerland and Beyond"</p>
    <p><span class="news-date">Dec 2024</span> — Contributed talk at <a href="https://swissdatacommunity.ch/alle-events/swisscommunity-day-on-data-2024/" target="_blank">Swiss Community Day on Data</a></p>
    <p><span class="news-date">Dec 2024</span> — Keynote and panel at EY National Trusted AI Conference with <a href="https://www.linkedin.com/in/marcstampfli/" target="_blank">Marc Stampfli</a> and <a href="https://www.linkedin.com/in/anne-scherer/" target="_blank">Anne Scherer</a></p>
    <p><span class="news-date">Nov 2024</span> — Invited talk at DeepMind, London on Linear Transformers and DeltaNet</p>
    <p><span class="news-date">Nov 2024</span> — <a href="https://www.srf.ch/wissen/wissens-chats/chat-kuenstliche-intelligenz-die-fachrunde-von-a-bis-z" target="_blank">SRF KI Fachrunde</a> appearance</p>
    <p><span class="news-date">Oct 2024</span> — Invited talk at AI+X conference at the Swiss AI Initiative workshop</p>
    <p><span class="news-date">Sep 2024</span> — Invited talk at <a href="https://ethz.ch/staffnet/de/news-und-veranstaltungen/intern-aktuell/archiv/2024/09/kompetenter-umgang-mit-ki.html" target="_blank">ETH-wide AI Upskilling</a> «Die Magie der KI entschlüsseln»</p>
    <p><span class="news-date">May 2024</span> — Invited talk at <a href="https://ieee.ch/2024/07/08/2024-general-assembly/" target="_blank">2024 IEEE Switzerland Section General Assembly</a></p>
    <p><span class="news-date">May 2024</span> — Invited talk at the Swiss publisher association (Verlegerverband) on Large Language Models and the Swiss AI Initiative</p>
    <p><span class="news-date">May 2024</span> — <a href="https://www.beyonder.ch/blog/ki-schwachstellen-entschlusselt-einblick-in-verborgene-risiken-und-manipulationen" target="_blank">Marketing Booster Podcast</a> appearance</p>
    <p><span class="news-date">Feb 2024</span> — Started a position as research scientist at the ETH AI Center</p>
    <p><span class="news-date">Oct 2023</span> — Started a postdoctoral position at ETHZ with Prof. Thomas Hofmann</p>
    <p><span class="news-date">Aug 2023</span> — Invited talk at IBM on Linear Transformers and DeltaNet</p>
    <p><span class="news-date">May 2023</span> — Defended my PhD on Fast Weight Programmers for Greater Systematic Generalisation in Language with distinction.</p>
  </div>
</section>

<section class="selected-publications">
  <h2>Selected Publications</h2>
  <div class="publication-items">
    <p><em>Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs</em><br>
    D. Fan, V. Sabolčec, M. Ansaripour, A.K. Tarun, M. Jaggi, A. Bosselut, I. Schlag — <a href="https://arxiv.org/abs/2504.06219" target="_blank">Preprint 2025</a></p>
    
    <p><em>INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge</em><br>
    A. Romanou, N. Foroutan, A. Sotnikova, Z. Chen, et al. — <a href="https://openreview.net/forum?id=k3gCieTXeY" target="_blank">ICLR 2024</a></p>
    
    <p><em>On the Effect of (Near) Duplicate Subwords in Language Modelling</em><br>
    A. Schäfer, T. Hofmann, I. Schlag, T. Pimentel — <a href="https://aclanthology.org/2024.findings-acl.571/" target="_blank">ACL 2024</a></p>
    
    <p><em>Large Language Model Programs</em><br>
    I. Schlag, S. Sukhbaatar, A. Celikyilmaz, W. Yih, J. Weston, J. Schmidhuber, X. Li — <a href="https://arxiv.org/abs/2305.05364" target="_blank">Preprint 2023</a></p>
    
    <p><em>A Modern Self-Referential Weight Matrix That Learns to Modify Itself</em><br>
    K. Irie*, I. Schlag*, R. Csordás, J. Schmidhuber — <a href="https://proceedings.mlr.press/v162/irie22b" target="_blank">ICML 2022</a></p>
    
    <p><em>Linear Transformers are Secretly Fast Weight Programmers</em><br>
    I. Schlag*, K. Irie*, J. Schmidhuber — <a href="https://proceedings.mlr.press/v139/schlag21a/" target="_blank">ICML 2021</a></p>
  </div>
  <p><a href="/research/" class="view-all-link">View all publications</a></p>
</section>

